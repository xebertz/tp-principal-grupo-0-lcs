= CNN implementado manualmente
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [2.8cm, 2.8cm, 2.8cm, 2.8cm]

== ¿Qué es una Red Neuronal Convolucional?

Las CNN son una clase especializada de redes neuronales profundas diseñadas para procesar y analizar datos de tipo grid, como imágenes y vídeos. Se destacan por su capacidad para capturar patrones espaciales en los datos mediante el uso de capas de convolución.

Cada una de ellas se encuentra conformada por una serie de capas, en donde cada una de ellas tiene una funcionalidad distinta. Primero, están las *capas de convolución*, estas capas aplican filtros sobre las imágenes con el objetivo de poder detectar mas eficientemente los bordes, texturas y formas. Por otro lado, también existen las denominadas *"Capas de Pooling"*, las cuales se utilizan para reducir la dimensionalidad espacial de las representaciones y hacer que la red sea más invariante a pequeñas traslaciones y variaciones. Finalmente, luego de varias capas de convolución y pooling, aparecen las *capas completamente conectadas*, estas capas utilizan las características aprendidas por las capas anteriores para asignar la entrada a clases específicas.

== Modelo Implementado

Nuestro modelo trabaja con un dataset creado por nosotros en base a otros dataset obtenidos de Kaggle. Para obtener nuestro dataset dar click https://www.kaggle.com/datasets/gonzajl/tumores-cerebrales-mri-dataset[aquí].

La implementación del modelo utilizando redes neuronales convolucionales es similar al que realizó el grupo 1 en el trabajo inicial. Los cambios realizados son principalmente con el objetivo de adaptarlo para que no sea binario, sino multiclase, en particular, el modelo puede clasificar en 4 clases distintas. La primera, es *glioma*, el cual es un tumor que se origina en el tronco encefálico, la médula espinal y el cerebelo. La segunda clasificación posible es *meningioma*, Un meningioma es un tumor que se origina en las membranas que rodean al cerebro y la médula espinal. El tercer tipo posible es el denominado *"pituitary tumors"*, el cual en español significa *"Tumores Hipofisarios"*, estos se encuentran en la base del cerebro. Finalmente, la última clasificación que considera el modelo se denomina *No tumor*, que como dice el nombre, hace referencia a cuando no se detecta ningún tumor en la imagen.

== Adaptación del modelo multiclase

Los cambios que se realizaron para que el modelo pasara de ser binario a multiclase (Considerando las 4 clases mencionadas anteriormente) no fueron muchos. El primero de los cambios requeridos fue al final del código, en donde se tuvo que modificar la función de pérdida o "loss", un modelo de clasificación binaria utiliza un método denominado *binary_crossentropy*, mientras que uno multiclase utiliza otro llamado *categorical_crossentropy*. Ahora, el método categorical_crossentropy requiere que las etiquetas de las imágenes estén en un formato en específico, afortunadamente, las etiquetas que teníamos ya estaban en el formato adecuado por lo que no fue necesario realizar una adaptación. El último cambio se realizó dentro de la sección de activación del modelo, en donde se utiliza una neurona densa denominada *Softmax*, la cual indica que el modelo tiene 4 neuronas en la capa de salida, una para cada una de las clases posibles.

== Entrenamiento y prueba

Se utilizaron distintas distribuciones de las 44 mil imágenes disponibles para entrenar el modelo, por cuestiones de recursos, de esas 44 mil pudimos utilizar eficazmente alrededor de 42 mil imágenes, ya que si se agregaban más tiraba error al momento de la ejecución de algunas secciones del código por falta de recursos.
La distribución más prometedora fue de 16 mil imágenes en total (12800 de entrenamiento y 3200 de prueba), balanceando todas las clases con 4000 imágenes cada una.

== Mejores resultados

=== 30400 imágenes de entrenamiento y 7600 de prueba

[source, console]
----
Epoch 1/10
950/950 [==============================] - 190s 200ms/step - loss: 0.0346 - accuracy: 0.9764 - val_loss: 0.0687 - val_accuracy: 0.9613
Epoch 2/10
950/950 [==============================] - 190s 200ms/step - loss: 0.0334 - accuracy: 0.9763 - val_loss: 0.0704 - val_accuracy: 0.9650
Epoch 3/10
950/950 [==============================] - 188s 198ms/step - loss: 0.0322 - accuracy: 0.9782 - val_loss: 0.0720 - val_accuracy: 0.9626
Epoch 4/10
950/950 [==============================] - 188s 198ms/step - loss: 0.0291 - accuracy: 0.9809 - val_loss: 0.0990 - val_accuracy: 0.9438
Epoch 5/10
950/950 [==============================] - 187s 197ms/step - loss: 0.0273 - accuracy: 0.9815 - val_loss: 0.0742 - val_accuracy: 0.9607
Epoch 6/10
950/950 [==============================] - 190s 200ms/step - loss: 0.0265 - accuracy: 0.9820 - val_loss: 0.0764 - val_accuracy: 0.9628
Epoch 7/10
950/950 [==============================] - 187s 197ms/step - loss: 0.0238 - accuracy: 0.9839 - val_loss: 0.0830 - val_accuracy: 0.9575
Epoch 8/10
950/950 [==============================] - 188s 197ms/step - loss: 0.0228 - accuracy: 0.9845 - val_loss: 0.0801 - val_accuracy: 0.9628
Epoch 9/10
950/950 [==============================] - 189s 199ms/step - loss: 0.0219 - accuracy: 0.9852 - val_loss: 0.0800 - val_accuracy: 0.9643
Epoch 10/10
950/950 [==============================] - 190s 200ms/step - loss: 0.0208 - accuracy: 0.9868 - val_loss: 0.0743 - val_accuracy: 0.9668
----

== Resultados por clase

[source, console]
----
Cantidad de predicciones: 7600
Etiquetas:   [G,  M,  P,  N]
Total:       [1920, 1893, 1868, 1919]
Correctas:   [1838, 1808, 1845, 1857]
Incorrectas: [82, 85, 23, 62]
----