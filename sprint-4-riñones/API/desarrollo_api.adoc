= API : Desarrollo y Testeo
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

=== API
Una API es un conjunto de definiciones y protocolos que se utilizan para diseñar e integrar el software de las aplicaciones. Permiten que los productos y servicios se comuniquen con otros, sin necesidad de saber cómo están implementados.
 
Una API utiliza *endpoints*, que son puntos de acceso o URLs específicas que se utilizan para realizar operaciones o solicitudes a través de la API. Cada endpoint está diseñado para llevar a cabo una función específica y proporciona una forma estructurada y estandarizada de interactuar con la API.

La API esta alojada en un repositorio de GitHub: https://github.com/Leandr0Fr/averia[API]

=== Necesidad
Tras desarrollar el modelo de Machine Learning sobre clasificación de imágenes con neumonía o no, hemos contemplado la necesidad de realizar una API para el uso de esta misma. En este contexto, hemos tenido el privilegio de desarrollar la API que facilita el acceso y la utilización del modelo.

== Desarrollo
Para la implementación de la API se utilizó el lenguaje Python con el Framework de Flask, y distintas librerías necesarias para la utilización del modelo y para la manipulación de imágenes.

=== Flask
Flask nos permite, de una manera rápida y sencilla, crear endpoints para el uso de la API y enlazar funciones a estas mismas. 

Además, para documentar la API y tener un campo de pruebas sin necesidad de consumirla bajo código, hemos utilizado *Swagger* mediante la librería _flask_restx_.

El siguiente ejemplo trata sobre un endpoint que retorna un _status_code_ 200, que significa que la API está activa. 

[source,python]
----
from flask_restx import Resource, Namespace
from .response_generation import response_generation

ns_ping = Namespace("ping")

@ns_ping.route("")
class Ping(Resource):
    def get(self):
        return response_generation({"message" : "API on!"}, 200)
----

Utilizando la librería _flask_restx_ generamos un endpoint "ping". Para crear la lógica de la ruta establecemos una clase y dentro de ella se genera una función con el nombre del verbo HTTP que vamos a utilizar, en este caso get. Luego, dentro de la función, se realiza la lógica de lo que va a retornar.

La función realiza un llamado a la función _response_generation_, esta función retorna un objeto response, donde almacena el map y el _status_code_ que recibe como parámetros. Además, se le agrega los permisos de *CORS*.

[source,python]
----
def response_generation(response_data, status):
    response = make_response(jsonify(response_data))
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.status_code = status
    return response
----

=== Implementación del modelo

Luego del desarrollo del modelo pre-entrenado mediante la utilización de las bibliotecas Keras y Tenserflow, se procedió a exportar los modelos ya entrenados y almacenarlos en un archivo de tipo .h5. Luego, como se vio anteriormente, un archivo de tipo .h5 tiene la característica de ser capaz de almacenar grandes cantidades de información de forma eficiente, por lo cual es el indicado para almacenar modelos que ya fueron entrenados.

Al obtener el archivo que contiene al modelo listo para ser usado, queda implementar una forma para poder adaptarlo al contexto que necesitamos dentro de nuestra API. Para esto, primero se debe obtener la imágen que será procesada por el modelo mediante un endpoint y un método HTTP-POST.

[source,python]
----
@ns_predict.route("/lyso")
class Predict(Resource):
    @ns_predict.expect(parser_lyso)
    def post(self):
        args = parser_lyso.parse_args()
        hermaturia = 1 if args['hermaturia'] else 0
        dolor_lumbar = 1 if args['dolor_lumbar'] else 0
        dolor_abdominal = 1 if args['dolor_abdominal'] else 0
        fiebre = 1 if args['fiebre'] else 0
        perdida_peso = 1 if args['perdida_peso'] else 0

        image = args['image']
        id = args['id_image']

        if image == None:
            return response_generation({"message": "ERROR! image not found"}, 404)
        if exists_id(CSV_LYSO, id):
            return response_generation({"message": "ERROR! existing ID"}, 400)
        is_int = isinstance(id, int)
        if not is_int:
            return response_generation({"message": "ERROR! ID is not int"}, 400)
        if image.filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            name = get_millsec()

            image.save(f"{IMAGES_LYSO}/{name}.png")
            response_data = {}
            class_probabilities = prediction_kidney(name) 

            for class_type, probability in class_probabilities:
                response_data[class_type.lower()] = probability

            append_predict_lyso(id, f"images/{name}.png", hermaturia,
                                dolor_lumbar, dolor_abdominal, fiebre, perdida_peso)
            return response_generation(response_data, 200)
        else:
            return response_generation({"message": "I'm a teapot!"}, 418)
----

Este código contiene toda la lógica que se obtiene mediante el consumo de la API. Es decir, contiene la obtención de la imagen (a la cual se le asigna un ID) y los datos del paciente ingresados.

[source,python]
----
def prediction_kidney(name):
    # Carga el modelo.
    model = tensorflow.keras.models.load_model(MODEL_LYSO)
    # Transforma la imagen para que coincidan con el modelo.
    img = Image.open(f"{IMAGES_LYSO}/{name}.png").convert("L")
    img = img.resize((224, 224))
    img_array = np.array(img)
    img_array = img_array / 255
    # Realiza la predicción
    class_labels = ["quiste", "piedra", "tumor", "normal"]
    predict = model.predict(np.expand_dims(img_array, axis=0))[0]
    probabilities = [(prob * 100) for prob in predict]
    return list(zip(class_labels, probabilities))
----

Como el modelo implementado es multiclase, es decir, que puede clasificar la imagen en más de 2 clases (en particular 4), este retorna un arreglo de tamaño 4. Dentro de dicho arreglo, se guardarán los resultados que obtuvo el modelo en cada una de las clases. La primera posición del arreglo representa las posibilidades de que la imagen procesada represente un quiste, mientras que el resto de las posiciones representan la probabilidad de que el diagnóstico sea piedra, tumor o un riñón normal, en ese orden.

=== Implementación endpoint Download

Tras haber realizado los modelos de inteligencia artificial, notamos que los modelos son estáticos, es decir, los modelos no son entrenan con los datos nuevos. 

Entonces, se decidió descargar las imágenes ingresadas en los diferentes modelos adjuntando un csv con el feedback del médico para un futuro entrenamiento de un nuevo modelo con los nuevos datos.

Existen 3 endpoints HTTP-GET para descargar un _.zip_ correspondiente a cada modelo.

.download_fred
[source,python]
----
@ns_download.route("/fred")
class Download(Resource):
    def get(self):
        to_zip(FOLDER_FRED, "fred")
        file = DOWNLOAD_FRED_ROUTE
        return send_file(file, as_attachment=True, download_name="fred.zip")
----

Se genera un archivo _.zip_ de la carpeta correspondiente al modelo seleccionado. La carpeta contiene el csv con los datos de las imágenes y una carpeta con las imágenes correspondiente. 

Para generar el _.zip_ se busca la ruta de la carpeta y utilizando la librería *shutil* se lo convierte a _.zip_. Luego, se mueve a la carpeta _download_.

.to_zip
[source,python]
----
def to_zip(route, name):
    folder = route
    name_zip = name
    route_save = "download/"
    shutil.make_archive(os.path.join(route_save, name_zip), 'zip', folder)
----