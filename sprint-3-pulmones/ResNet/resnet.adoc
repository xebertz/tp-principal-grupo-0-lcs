= Modelo ResNet: Entrenamiento y pruebas
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Modelo

_ResNet_, que es la abreviatura de "Redes Residuales" (en inglés, "Residual Networks"), es un modelo preentrenado que ha demostrado ser muy efectivo en tareas de clasificación de imágenes, detección de objetos, segmentación semántica y otras tareas relacionadas con el procesamiento de imágenes. Ha establecido récords en varios conjuntos de datos de referencia y se ha convertido en una base importante para muchas aplicaciones de visión por computadora.

Utilizamos la variante _ResNet50V2_ de dicho modelo preentrenado. Para incorporarlo en nuestra aplicación, importamos el modelo y le agregamos una capa de entrada (input layer) diseñada para adaptarse a nuestras imágenes, una capa de pooling y una capa de salida. Para aprovechar la técnica de _transfer learning_, hemos congelado el modelo, lo que significa que hemos mantenido los pesos que adquirió durante su entrenamiento previo con el conjunto de datos _ImageNet_.

== Entrenamiento

Realizamos los entrenamientos utilizando nuestro https://www.kaggle.com/datasets/gonzajl/neumona-x-rays-dataset[dataset] diseñado para la detección de neumonía en imágenes de rayos X de tórax. Este conjunto de datos consta de un total de 10,498 imágenes, de las cuales 5,249 son radiografías de pacientes diagnosticados con neumonía y las restantes 5,249 corresponden a pacientes que no presentan la enfermedad.

El entrenamiento se realizó utilizando el siguiente modelo:

[source, python]
----
base_model = tf.keras.applications.ResNet50V2(
    include_top=False,
    weights="imagenet",
    input_shape=(224, 224, 3),
)

base_model.trainable = False

num_classes = 2
x = layers.GlobalAveragePooling2D()(base_model.output)
output = layers.Dense(num_classes, activation="softmax")(x)
model = Model(inputs=base_model.input, outputs=output)
----

Luego, el modelo se compiló de la siguiente manera:

[source, python]
----
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["categorical_accuracy"])
----

=== Entrenamiento de 10 épocas

Se utilizó el 80% de las imágenes para el entrenamiento del modelo y el 20% restante para las pruebas, lo que se traduce en 8,398 imágenes de entrenamiento y 2,100 imágenes de prueba. Durante las diez épocas de entrenamiento, los resultados fueron los siguientes:

[source, console]
----
Epoch 1/10
2023-10-19 15:51:50.138173: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5056536576 exceeds 10% of free system memory.
263/263 [==============================] - 210s 792ms/step - loss: 0.1984 - categorical_accuracy: 0.9206 - val_loss: 0.1269 - val_categorical_accuracy: 0.9533
Epoch 2/10
263/263 [==============================] - 205s 781ms/step - loss: 0.1230 - categorical_accuracy: 0.9565 - val_loss: 0.1051 - val_categorical_accuracy: 0.9605
Epoch 3/10
263/263 [==============================] - 205s 781ms/step - loss: 0.1041 - categorical_accuracy: 0.9639 - val_loss: 0.0924 - val_categorical_accuracy: 0.9662
Epoch 4/10
263/263 [==============================] - 206s 782ms/step - loss: 0.0936 - categorical_accuracy: 0.9670 - val_loss: 0.0855 - val_categorical_accuracy: 0.9695
Epoch 5/10
263/263 [==============================] - 206s 784ms/step - loss: 0.0873 - categorical_accuracy: 0.9693 - val_loss: 0.0839 - val_categorical_accuracy: 0.9695
Epoch 6/10
263/263 [==============================] - 206s 784ms/step - loss: 0.0777 - categorical_accuracy: 0.9721 - val_loss: 0.0757 - val_categorical_accuracy: 0.9733
Epoch 7/10
263/263 [==============================] - 204s 777ms/step - loss: 0.0711 - categorical_accuracy: 0.9759 - val_loss: 0.0817 - val_categorical_accuracy: 0.9667
Epoch 8/10
263/263 [==============================] - 205s 781ms/step - loss: 0.0678 - categorical_accuracy: 0.9762 - val_loss: 0.0798 - val_categorical_accuracy: 0.9729
Epoch 9/10
263/263 [==============================] - 205s 778ms/step - loss: 0.0639 - categorical_accuracy: 0.9780 - val_loss: 0.0670 - val_categorical_accuracy: 0.9748
Epoch 10/10
263/263 [==============================] - 207s 787ms/step - loss: 0.0584 - categorical_accuracy: 0.9806 - val_loss: 0.0662 - val_categorical_accuracy: 0.9729
----

Es relevante señalar que la advertencia que se muestra al principio indica que no es factible entrenar el modelo con un conjunto de datos más extenso debido a limitaciones de memoria del sistema, lo que impide considerar la opción de ampliar el conjunto de datos para mejorar la predicción.

Con los datos obtenidos del entrenamiento, es posible generar gráficos que permitan una visualización más clara de la evolución del modelo a lo largo de su entrenamiento.

image::imgs/graficos-resultados-1.png[]

Como se puede apreciar, se logró una precisión del 98% en el conjunto de entrenamiento y una precisión del 97% en el conjunto de pruebas.

Posteriormente, se procedió a evaluar el modelo utilizando las 2,100 imágenes del conjunto de pruebas, y se registraron los siguientes resultados:

[source, console]
----
66/66 [==============================] - 43s 633ms/step
Cantidad de predicciones: 2100
Etiquetas:   [neumonia, no-neumonia]
Total:       [1051, 1049]
Correctas:   [1035, 1008]
Incorrectas: [16, 41]
----

=== Entrenamiento de 20 épocas

De manera similar al entrenamiento anterior, se empleó el 80% de las imágenes para entrenar el modelo, reservando el 20% restante para las pruebas. Durante las veinte épocas de entrenamiento, se obtuvieron los siguientes resultados:

[source, console]
----
Epoch 1/20
2023-10-19 16:34:49.532354: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5056536576 exceeds 10% of free system memory.
263/263 [==============================] - 210s 790ms/step - loss: 0.2093 - categorical_accuracy: 0.9132 - val_loss: 0.1519 - val_categorical_accuracy: 0.9448
Epoch 2/20
263/263 [==============================] - 206s 783ms/step - loss: 0.1288 - categorical_accuracy: 0.9552 - val_loss: 0.1046 - val_categorical_accuracy: 0.9633
Epoch 3/20
263/263 [==============================] - 205s 780ms/step - loss: 0.1071 - categorical_accuracy: 0.9624 - val_loss: 0.0961 - val_categorical_accuracy: 0.9652
Epoch 4/20
263/263 [==============================] - 205s 779ms/step - loss: 0.0973 - categorical_accuracy: 0.9653 - val_loss: 0.0867 - val_categorical_accuracy: 0.9695
Epoch 5/20
263/263 [==============================] - 207s 786ms/step - loss: 0.0857 - categorical_accuracy: 0.9715 - val_loss: 0.0793 - val_categorical_accuracy: 0.9724
Epoch 6/20
263/263 [==============================] - 205s 780ms/step - loss: 0.0785 - categorical_accuracy: 0.9730 - val_loss: 0.0765 - val_categorical_accuracy: 0.9719
Epoch 7/20
263/263 [==============================] - 204s 778ms/step - loss: 0.0729 - categorical_accuracy: 0.9764 - val_loss: 0.0722 - val_categorical_accuracy: 0.9733
Epoch 8/20
263/263 [==============================] - 208s 791ms/step - loss: 0.0669 - categorical_accuracy: 0.9775 - val_loss: 0.0673 - val_categorical_accuracy: 0.9767
Epoch 9/20
263/263 [==============================] - 208s 793ms/step - loss: 0.0642 - categorical_accuracy: 0.9794 - val_loss: 0.0664 - val_categorical_accuracy: 0.9767
Epoch 10/20
263/263 [==============================] - 208s 791ms/step - loss: 0.0610 - categorical_accuracy: 0.9788 - val_loss: 0.0657 - val_categorical_accuracy: 0.9752
Epoch 11/20
263/263 [==============================] - 210s 800ms/step - loss: 0.0577 - categorical_accuracy: 0.9809 - val_loss: 0.0628 - val_categorical_accuracy: 0.9781
Epoch 12/20
263/263 [==============================] - 207s 787ms/step - loss: 0.0522 - categorical_accuracy: 0.9821 - val_loss: 0.0637 - val_categorical_accuracy: 0.9810
Epoch 13/20
263/263 [==============================] - 206s 784ms/step - loss: 0.0518 - categorical_accuracy: 0.9832 - val_loss: 0.0596 - val_categorical_accuracy: 0.9781
Epoch 14/20
263/263 [==============================] - 207s 788ms/step - loss: 0.0486 - categorical_accuracy: 0.9850 - val_loss: 0.0642 - val_categorical_accuracy: 0.9776
Epoch 15/20
263/263 [==============================] - 207s 788ms/step - loss: 0.0469 - categorical_accuracy: 0.9842 - val_loss: 0.0677 - val_categorical_accuracy: 0.9767
Epoch 16/20
263/263 [==============================] - 207s 786ms/step - loss: 0.0440 - categorical_accuracy: 0.9862 - val_loss: 0.0544 - val_categorical_accuracy: 0.9819
Epoch 17/20
263/263 [==============================] - 205s 781ms/step - loss: 0.0417 - categorical_accuracy: 0.9876 - val_loss: 0.0545 - val_categorical_accuracy: 0.9814
Epoch 18/20
263/263 [==============================] - 208s 791ms/step - loss: 0.0401 - categorical_accuracy: 0.9888 - val_loss: 0.0813 - val_categorical_accuracy: 0.9700
Epoch 19/20
263/263 [==============================] - 207s 788ms/step - loss: 0.0374 - categorical_accuracy: 0.9888 - val_loss: 0.0537 - val_categorical_accuracy: 0.9843
Epoch 20/20
263/263 [==============================] - 207s 789ms/step - loss: 0.0348 - categorical_accuracy: 0.9919 - val_loss: 0.0519 - val_categorical_accuracy: 0.9800
----

Para visualizar estos resultados, se generaron los siguientes gráficos:

image::imgs/graficos-resultados-2.png[]

Los resultados reflejan una impresionante precisión del 99% en el conjunto de entrenamiento y un sólido 98% en el conjunto de pruebas, además de una pérdida excepcionalmente baja.

Al evaluar el modelo con las 2,100 imágenes del conjunto de pruebas, se obtuvieron los siguientes resultados:

[source, console]
----
66/66 [==============================] - 43s 633ms/step
Cantidad de predicciones: 2100
Etiquetas:   [neumonia, no-neumonia]
Total:       [1074, 1026]
Correctas:   [1054, 1004]
Incorrectas: [20, 22]
----

Estos resultados muestran el desempeño del modelo en la clasificación de las imágenes de prueba, con un desglose de predicciones correctas e incorrectas en las categorías "neumonía" y "no-neumonía".

== Conclusión

