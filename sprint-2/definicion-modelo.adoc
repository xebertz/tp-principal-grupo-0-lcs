= TP Principal - Laboratorio de Construcción de Software: Sprint 2
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

Como ya se mencionó, el objetivo del proyecto es desarrollar un software que permita diagnosticar enfermedades de distintas partes del cuerpo a través de imágenes. El software está dirigido a todos profesionales de la salud que requieran utilizarlo.

Para este sprint, nuestro objetivo es desarrollar y hacer el deploy de un modelo que determine si un paciente tiene o no un tumor, y de qué tipo, a través de imágenes de resonancia magnética.

== Objetivos del documento

Una vez establecido el objetivo del trabajo, procedimos a realizar las tareas necesarias para el preprocesamiento de datos y el entrenamiento de distintos modelos, tantos preentrenados como manuales.

En este documento expondremos cómo preparamos los datos, qué modelos entrenamos y cuál es el elegido para nuestro problema. También explicaremos las distintas decisiones tomadas durante el desarrollo.

== Metodología de trabajo

Debido a la necesidad de entrenar distintos modelos, fueron divididos por miembros del equipo. Cada miembro trabajó en su entorno de Saturn Cloud de manera autónoma, y al finalizar los entrenamientos elegimos un modelo para realizar el deploy.

También fueron necesarias tareas de preparación de datos, deploy y gestión, las cuales fueron asignadas a miembros específicos del equipo de trabajo.

.división de tareas del equipo de trabajo
[cols="3*", options="header"]
|===
|Encargado         |Tarea

|Villalba, Gastón  |Tomar mate, gestión
|Ebertz, Ximena    |Desarrollo de modelos VGG16, VGG19, Xception y Transformada de Hough, gestión
|López, Gonzalo    |Preparación de datos y desarrollo de modelos ResNet y EfficientNetV2
|Franco, Leandro   |Deploy y desarrollo de modelo SVM, preparación de entorno
|Venditto, Pedro   |Desarrollo de modelos CNN Manual, InceptionResNet y Mask R - CNN, preparación de entorno
|===

== Datos

Determinamos que los siguientes _datasets_ serían útiles para nuestro trabajo:

- Dataset 1: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset[brain-tumor-mri-dataset] con 7022 imágenes.
- Dataset 2: https://www.kaggle.com/datasets/mohammadhossein77/brain-tumors-dataset[brain-tumors-dataset] con 21672 imágenes.

Decidimos que la mejor opción sería combinarlos y subirlos a Kaggle, ya que, de esta forma, todos los miembros pueden utilizarlo, sin realizar demasiadas tareas de preprocesamiento por código.

El dataset generado se encuentra https://www.kaggle.com/datasets/gonzajl/tumores-cerebrales-mri-dataset/data[acá].

== Modelos probados

Decidimos que la mejor opción era probar diversos modelos, para utilizar el mejor en el desarrollo final, y reutilizar los otros en caso que sea necesario.

Probamos distintos modelos, algunos preentrenados y otros manuales:

* *ResNet:* La aquitectura ResNet tiene diversas variantes, entre las cuales están ResNet50, ResNet50V2, ResNet152, ResNet152V2. De estas, la que mejor resultados arrojó fue ResNet50V2, con un 93% de precisión en las pruebas.

* *SVM:*

* *Xception:*

* *CNN Manual:*

* *Inception ResNet:*

* *VGG16:*

* *Transformada de Hough:*

== Modelos descartados

* *Mask R CNN:*

* *VGG19:*

