= TP Principal - Laboratorio de Construcción de Software: Sprint 4
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

Con la finalidad de cumplir los objetivos núcleo del sistema, ampliarlo y mejorar el desarrollo previo, nos pusimos los siguientes objetivos para este sprint:

1. Implementar la base de datos requerida para el reentrenamiento del modelo.
2. Desarrollar un modelo de detección de enfermedades renales.
3. Integrar las soluciones del equipo con las del proyecto.

== Objetivos del documento

Luego de establecer los objetivos realizamos la división de tareas, para iniciar con el desarrollo y lograr el cumplimiento de todas las metas.

En este documento expondremos el trabajo realizado durante el sprint, la división de tareas realizada y los distintos problemas que se presentaron durante estas dos semanas.

== Metodología de trabajo

Como se puede ver en la división de tareas, el equipo trabajó en dos grupos.

.división de tareas del equipo de trabajo
[cols="1,3", options="header"]
|===
|Encargado         |Tareas
|Villalba, Gastón  |Corregir documentación previa, gestión
|Ebertz, Ximena    |Búsqueda de datasets, búsqueda de información del problema, creación del dataset, CNN Manual, Xception, definición de arquitectura MDER, conexión con equipo de datos, refinamiento de modelo, gestión
|López, Gonzalo    |Investigación sobre BBDD, búsqueda de datasets, búsqueda de información del problema, creación del dataset, subir dataset de riñones a Kaggle, ResNet50V2, SVM
|Franco, Leandro   |Investigación sobre BBDD, capacitación en bases de datos, implementación de BBDD con API, deploy modelo de enfermedades renales, refinamiento API, conexión con equipo de datos
|Venditto, Pedro   |Capacitación en bases de datos, implementación de BBDD con API, investigación FileServer, implementación FileServer, deploy Modelo de Enfermedades Renales, refinamiento API, conexión con equipo de datos
|===

Se definió que Franco, Leandro y Venditto, Pedro trabajarían desarrollando la base de datos y actualizando la API para cumplir con el primer objetivo. Por otra parte, Ebertz, Ximena y López, Gonzalo trabajarían principalmente desarrollando el modelo, para cumplir con el segundo objetivo. Luego, se trabajaría en conjunto para la integración de nuestra API con el resto del proyecto, y así cumplir con el tercer objetivo.

== Datos

Determinamos que los siguientes datasets serían útiles para nuestro trabajo:

* Dataset 1: https://www.kaggle.com/datasets/nazmul0087/ct-kidney-dataset-normal-cyst-tumor-and-stone[CT KIDNEY DATASET: Normal-Cyst-Tumor and Stone]
* Dataset 2: https://www.kaggle.com/datasets/mohammedrizwanmalik/kidney-stones-mri-and-ct-scans[Kidney Stones Mri and CT scans]
* Dataset 3: https://www.kaggle.com/datasets/raagbhutani/kidneystone[KidneyStone]
* Dataset 4: https://www.kaggle.com/datasets/arjunbasandrai/medical-scan-classification-dataset[Medical Scan Classification Dataset]

Como en el sprint previo, creamos un dataset y lo subimos a Kaggle. El dataset se encuentra https://www.kaggle.com/datasets/gonzajl/riones-cyst-stone-tumor-normal-dataset[acá].

== Modelos

De los diversos modelos seleccionados para el proyecto, entrenamos sólo dos. Estos fueron:

* *ResNet50V2:* alcanzó un porcentaje de precisión del 95% en las pruebas, para 2352 imágenes.

* *CNN Manual:* alcanzó un porcentaje de precisión del 99.9% en las pruebas, para 2352 imágenes.

La elección de entrenar únicamente estos modelos no fue trivial.

Debido al ajustado tiempo para realizar tareas tan importantes, nuestra primer acción fue dividir el equipo para cumplir con lo requerido. No obstante, esto implica una menor cantidad de tiempo para entrenar un modelo y que sea lo suficientemente bueno para el proyecto. Por este motivo, definimos una calidad para cada modelo, basándonos en su eficacia en los sprints previos. Esta calidad corresponde a un valor entre 1 y 4, siendo:

* *1*: Modelo muy bueno, con 95% o más de precisión en promedio.
* *2*: Modelo bueno, con 90% o más de precisión en promedio.
* *3*: Modelo regular, con 80% o más de precisión en promedio.
* *4*: Modelo malo, con menos de 80% de precisión en promedio.

También, calculamos el tiempo que tarda cada modelo en entrenar en el mejor caso, para diez vueltas de entrenamiento.

En base a esta información, generamos la siguiente tabla:

[cols="^50,^30,^20", options="header"]
|===
|Modelo             |Tiempo mínimo  |Calidad
|CNN Manual         |00:19:23       |1
|EfficientNetV2     |1:03:45        |3
|InceptionResNetV2  |1:25:23        |2
|ResNet50V2         |0:44:51        |1
|SVM                |0:17:23        |1
|VGG16              |1:02:23        |3
|Xception           |1:10:23        |2
|===

Luego, priorizamos el entrenamiento de los modelos con mayor calidad y menor tiempo de entrenamiento. Estos fueron, por orden de prioridad, *SVM*, *CNN Manual* y *ResNet50V2*. Como *SVM* es un modelo binario y nuestro problema no lo es, fue descartado y *Xception* tomó su lugar, quedando el siguiente orden: *CNN Manual*, *ResNet50V2* y *Xception*. Sin embargo, este último modelo no fue entrenado debido a los excelentes resultados de los modelos entrenados previamente a él.

El modelo seleccionado para ser utilizado en el proyecto fue *CNN Manual*, debido a sus excepcionales resultados. Este modelo es el resultado de una modificación en la arquitectura de nuestro modelo manual previo, añadiéndole capas con mayor cantidad de neuronas. También se utilizó la función "Sigmoid" para la capa final, que determina un peso para cada clase en relación con las demás, lo que genera que la suma de todas las predicciones sea distinta de uno (como sucede con la función "Softmax"). Se determinó, durante el refinamiento del modelo, que Sigmoid es la mejor opción para nuestro modelo debido a que mejora las predicciones, obteniendo resultados más certeros.

== Entrevistas

Para este sprint decidimos no realizar entrevistas. El motivo de esta elección fue el tiempo limitado con respecto a las tareas a realizar. La importancia de la integración es mayor, por lo que decidimos utilizar nuestra investigación para complementar el desarrollo del modelo, sabiendo que esto no reemplaza la entrevista con un profesional, pero para este dominio con la investigación fue suficiente. Luego, el modelo se puede refinar con el feedback del médico.

== Deploy

Como en los sprints previos, realizamos el deploy del modelo en nuestra https://averiapi-4vtuhnxfba-uc.a.run.app/[API]. El endpoint del modelo correspondiente a este sprint, denominado _lyso_, recibe la imagen, el ID de la misma, y cinco booleanos como información extra, correspondientes a síntomas de las enfermedades. Estos son: _hematuria_, _dolor_lumbar_, _dolor_abdominal_, _fiebre_ y _perdida_peso_. El modelo devuelve un JSON con las clases y la probabilidad correspondiente a cada una de ellas, de 0 al 100. El valor máximo es el correspondiente a la clase predecida.

== Base de datos