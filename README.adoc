= TP Principal - Laboratorio de Construcción de Software: Sprint 2
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

Como ya se mencionó, el objetivo del proyecto es desarrollar un software que permita diagnosticar enfermedades de distintas partes del cuerpo a través de imágenes. El software está dirigido a todos profesionales de la salud que requieran utilizarlo.

Para este sprint, nuestro objetivo es desarrollar y hacer el deploy de un modelo que determine si un paciente tiene o no un tumor, y de qué tipo, a través de imágenes de resonancia magnética.

== Objetivos del documento

Una vez establecido el objetivo del trabajo, procedimos a realizar las tareas necesarias para el preprocesamiento de datos y el entrenamiento de distintos modelos, tantos preentrenados como manuales.

En este documento expondremos cómo preparamos los datos, qué modelos entrenamos y cuál es el elegido para nuestro problema. También explicaremos las distintas decisiones tomadas durante el desarrollo.

== Metodología de trabajo

Debido a la necesidad de entrenar distintos modelos, fueron divididos por miembros del equipo. Cada miembro trabajó en su entorno de Saturn Cloud de manera autónoma, y al finalizar los entrenamientos elegimos un modelo para realizar el deploy.

También fueron necesarias tareas de preparación de datos, deploy y gestión, las cuales fueron asignadas a miembros específicos del equipo de trabajo.

.división de tareas del equipo de trabajo
[cols="2*", options="header"]
|===
|Encargado         |Tarea
|Villalba, Gastón  |Tomar mate, gestión
|Ebertz, Ximena    |Desarrollo de modelos VGG16, VGG19, Xception y Transformada de Hough, gestión
|López, Gonzalo    |Preparación de datos y desarrollo de modelos ResNet y EfficientNetV2
|Franco, Leandro   |Deploy y desarrollo de modelo SVM, preparación de entorno
|Venditto, Pedro   |Desarrollo de modelos CNN Manual, InceptionResNet y Mask R - CNN, preparación de entorno
|===

== Datos

Determinamos que los siguientes _datasets_ serían útiles para nuestro trabajo:

- Dataset 1: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset[brain-tumor-mri-dataset] con 7022 imágenes.
- Dataset 2: https://www.kaggle.com/datasets/mohammadhossein77/brain-tumors-dataset[brain-tumors-dataset] con 21672 imágenes.

Decidimos que la mejor opción sería combinarlos y subirlos a Kaggle, ya que, de esta forma, todos los miembros pueden utilizarlo, sin realizar demasiadas tareas de preprocesamiento por código.

El dataset generado se encuentra https://www.kaggle.com/datasets/gonzajl/tumores-cerebrales-mri-dataset/data[acá].

== Modelos probados

Decidimos que la mejor opción era probar diversos modelos, para utilizar el mejor en el desarrollo final, y reutilizar los otros en caso que sea necesario.

Probamos distintos modelos, algunos preentrenados y otros manuales:

* *ResNet:* La aquitectura ResNet tiene diversas variantes, entre las cuales están ResNet50, ResNet50V2, ResNet152, ResNet152V2. De estas, la que mejor resultados arrojó fue ResNet50V2, con un 93% de precisión en las pruebas para 2200 imágenes.

* *SVM:* Este modelo es binario. Llevando nuestro problema a un problema binario, obtuvimos un 96% de precisión en las pruebas. Sin embargo, no será utilizado por no ser multiclase.

* *Xception:* Este modelo alcanzó un porcentaje superior al 90% de precisión en las pruebas, para 3200 imágenes.

* *CNN Manual:* Este modelo fue el más liviano y rápido de todos, y obtuvo resultados sorprendentes: 92% de precisión en las pruebas, para 3200 imágenes.

* *Inception ResNetV2:* Este modelo alcanzó un porcentaje superior al 86% de precisión en las pruebas, para 2600 imágenes. Sin embargo, fue entrenado en una sola vuelta por su complejidad.

* *VGG16:* Este modelo, al ser pesado, no permitió muchas imágenes de entrenamiento ni de prueba. Obtuvo un 83% de precisión en las pruebas, para 800 imágenes.

* *Transformada de Hough:* Esta técnica fue utilizada para encontrar círculos en imagenes de resonancia magnética, pero no dio los resultados esperados.

== Modelos descartados

Durante el proceso de entrenamiento se determinó que ciertos modelos no valían la pena ser entrenados. Estos son *Mask R CNN* y *VGG19*. El primero se descartó por problemas de compatibilidad entre versiones de kernel y Tenserflow necesarias para la implementación de este modelo. Solucionar este problema sería muy costoso y no valía la pena debido a los buenos resultados obtenidos en otros modelos. El segundo se descartó debido a que es similar a *VGG16*, y es uno de los que demostró peor performance y resultados más pobres. Entrenarlo llevaría mucho tiempo y tampoco es necesario.

== Modelo seleccionado

El modelo elegido fue *CNN Manual*, debido a su alto nivel de precisión. *ResNet50V2* quedó como segunda opción, ya que a pesar de tener un nivel de precisión más alto que *CNN Manual*, fue entrenado con menos imágenes y cuenta con una performance inferior.

== Deploy
Tras haber exportado el modelo seleccionado se empezó con el desarrollo de una API para facilitar el uso del modelo.
Se utilizó Python junto el Framework de Flask para desarrollar la API. Tras haber desarrollado la API, se procedió a desplegar la aplicación utilizando el PaaS de Railway, aunque en primer lugar se decidió por FL0, últimamente la plataforma tiene mal funcionamiento.

La API cuenta con 2 endpoints:

* /ping: Mediante una solicitud HTTP-GET retorna un JSON con el siguiente mensaje: "API on!", y un _status_code_ 200.

* /predict: Mediante una solicitud HTTP-POST se le debe envíar un binario (Imagen) y retorna un JSON con los siguientes posibles mensajes: "Glioma", "Meningioma", "Pituitary" y "No_tumor". En caso contrario de no ser un binario aceptado, retorna un _status_code_ 418.

La API se puede ingresar desde: https://tumorapi-production.up.railway.app/
. En la misma se puede encontrar un pequeño resumen de como consumir la API.