= TP Principal - Laboratorio de Construcción de Software: Sprint 3
Ebertz Ximena <xebertz@campus.ungs.edu.ar>; Franco Leandro <leandro00fr@gmail.com>; López Gonzalo <gonzagonzalopez20@gmail.com>; Venditto Pedro <pedrovenditto41@gmail.com>; Villalba Gastón <gastonleovillalba@gmail.com>;
v1, {docdate}
:toc:
:title-page:
:toc-title: Secciones
:numbered:
:source-highlighter: highlight.js
:tabsize: 4
:nofooter:
:pdf-page-margin: [3cm, 3cm, 3cm, 3cm]

== Introducción

Con la finalidad de ampliar el sistema y mejorar el desarrollo previo, nos pusimos los siguientes objetivos para este sprint:

1. Entrevistar un profesional para mejorar el modelo de detección de tumores cerebrales
2. Mejorar la API desarrollada en el sprint anterior
3. Desarrollar un modelo de detección de neumonía a partir de imágenes de rayos X de tórax
4. Realizar el deploy del modelo desarrollado

== Objetivos del documento

Luego de establecer los objetivos realizamos la división de tareas, para iniciar con el desarrollo y lograr el cumplimiento de todas las metas.

En este documento expondremos el trabajo realizado durante el sprint, la división de tareas realizada y los distintos problemas que se presentaron durante estas dos semanas.

== Metodología de trabajo

Debido a la naturaleza divergente de las tareas establecidas como objetivo, dividimos las tareas dependiendo de la semana.

.división de tareas del equipo de trabajo
[cols="3*", options="header"]
|===
|Encargado         |Tareas semana 1 |Tareas semana 2
|Villalba, Gastón  |Entrevistar neurólogo, gestión|Corregir documentación previa, entrevista con neumonóloga pediátrica, gestión
|Ebertz, Ximena    |Búsqueda de datasets, entrevistar neurólogo, búsqueda de información del problema, gestión|Creación del dataset, preparación de entorno de trabajo extra, CNN Manual, Xception, Transformada de Hough, gestión
|López, Gonzalo    |Búsqueda de datasets, búsqueda de información del problema|Creación del dataset, preparación de entorno de trabajo extra, EfficientNetV2, ResNet50V2, investigación sobre bases de datos
|Franco, Leandro   |Búsqueda de datasets, búsqueda de información del problema|Refinamiento API MDTC, preparación de entorno de trabajo extra, deploy de API MDEP, refinamiento de API MDEP
|Venditto, Pedro   |Búsqueda de datasets, entrevistar neurólogo, búsqueda de información del problema|Deploy de API MDEP, refinamiento API MDTC, preparación de entorno de trabajo extra, entrevista con neumonóloga pediátrica
|===

Esta división se realizó teniendo en cuenta distintos *riesgos* y *cambios* a los que nos vimos expuestos.

=== Cambios

Durante el transcurso de la segunda semana, se presentó un cambio de alcance: la necesidad del feedback del médico. Nosotros lo considerábamos como un trabajo a futuro, por lo que nos generó un cambio en la planificación. Esto implica contar con una base de datos propia y generar un nuevo canal de comunicación entre nuestro equipo y el de datos. También, esta cambio implica la modificación de la API, ya que debemos recibir información que no teníamos en cuenta para esta instancia.

=== Riesgos

Los riesgos se presentaron en la segunda semana del sprint. Tuvimos un miembro del equipo ausente dos días por motivos de estudio. A parte, nos encontramos con que el servidor con el cual trabajamos nos limitó la cantidad de horas mensuales a 30, siendo que antes contábamos con 150.

.riesgos enfrentados
[cols="8*", options="header"]
|===
|Riesgo        |Prob |Sev |Exp |Mitigación |Contingencia   |Resp |Sem
|Ausencia de miembros del equipo el 2023-10-18 y 2023-10-19 por motivos de estudio |3 |3 |9 |Definir reemplazantes, planificar ausencias |Reemplazos |GV, XE |2
|Dificultades en la integración con otros grupos del proyecto |2 |3 |6 |Establecer estándares de comunicación entre APIs |Comunicar por los medios acordados los inconvenientes surgidos |GV, XE |2
|Pérdida de posibilidad de trabajo en el entorno |1 |3 |3 |Backups periódicos, alternativas de entornos |Cambiar de entorno de trabajo, restablecer backup |GL, XE  |2
|===

=== Soluciones

En base a esto, establecimos lo siguiente:

* Ausencia de miembros del equipo: Ximena Ebertz sería el reemplazo de Pedro Venditto
* Dificultades en la integración con otros grupos del proyecto: el equipo tendría una reunión con los otros equipos, para definir nuevamente la arquitectura y prever problemas de integración
* Pérdida de posibilidad de trabajo en el entorno: el equipo crearía entornos de trabajo extra, para su utilización en caso de agote de horas del entorno principal
* Feedback del médico: Gonzalo López investigaría sobre bases de datos a utilizar para nuestra infraestructura

== Datos

Determinamos que los siguientes datasets serían útiles para nuestro trabajo:

* Dataset 1: https://www.kaggle.com/datasets/pcbreviglieri/pneumonia-xray-images[pneumonia-xray-images], con 5856 imágenes.
* Dataset 2: https://www.kaggle.com/datasets/vivek468/beginner-chest-xray-image-classification[beginner-chest-xray-image-classification], con 7944 imágenes.

Como en el sprint previo, creamos un dataset y lo subimos a Kaggle. El dataset se encuentra https://www.kaggle.com/datasets/gonzajl/neumona-x-rays-dataset[acá].

Al ser este un problema binario, existen dos alternativas para gestionar las etiquetas de las clases:

1. Que la etiqueta sea un único número entre 0 y 1. El valor 0 correspondería a una clase, y el valor 1 a otra.
2. Que la etiqueta sea una array de dos posiciones, en la que cada posición corresponde a la probabilidad de que la imagen pertenezca a la clase correspondiente a esa posición. La suma de ambas posiciones debe ser 1.

Esta segunda opción la que utilizamos en modelos multiclase, ya que la cantidad de elementos del array puede aumentar. Como fue utilizada en el modelo anterior, decidimos utilizarla nuevamente en este sprint, aunque sea menos convencional para modelos de clasificación binaria. Esta decisión se tomó por cuestiones de diseño, para que los demás equipos no deben aprender a interpretar otra forma de mostrar los resultados, ya que es innecesario.

== Modelos probados

* *ResNet50V2:* 

* *SVM:* 

* *Xception:* 

* *CNN Manual:* 

* *Inception ResNetV2:* 

== Modelos descartados

Debido a las dificultades encontradas en el sprint anterior, decidimos que los modelos *VGG19* y *Mask R CNN* ya no serán tomados en cuenta para desarrollos futuros. El modelo *VGG16* fue descartado debido a su lentitud en el entrenamiento. Como consecuencia de la disminución de horas de trabajo en el entorno y debido a que ya teníamos modelos funcionales que realizaban muy buenas predicciones, consideramos que no era necesario entrenarlo, ya que se trata de un modelo lento y, en nuestra experiencia, no alcanza niveles de precisión muy altos. La *Transformada de Hough* fue descartada ya que, en este contexto, no necesitamos detectar circunferencias en las imágenes.

== Modelo seleccionado

Nuevamente, entre las opciones a elegir para el modelo final estuvieron *ResNet50V2* y *CNN Manual*. En este caso, añadimos a *SVM* como una alternativa, aunque fue descartado debido a su tamaño. Ambos modelos restantes tienen niveles de precisión muy parecidos, por lo que la decisión no fue trivial. Finalmente, el modelo elegido fue *ResNet50V2* por dos motivos:

1. Es un modelo que no utilizamos previamente
2. Los errores que comete son parejos en las clases. CNN Manual comete más errores en las imágenes de pacientes sin neumonía

== Entrevistas

Realizamos dos entrevistas. La primera fue con el doctor Kosac, neurólogo. Fue llevada a cabo en su consultorio en Recoleta, el 11 de octubre de 2023. El doctor definió distintos aspectos a tener en cuenta para la detección de tumores cerebrales, previo a la resonancia magnética.
La segunda entrevista se realizó a la doctora Tapia, neumonóloga especialista en niños. Fue llevada a cabo de forma virtual, el 21 de octubre de 2023. La doctora explicó los distintos tipos de neumonía y sus síntomas.

== Deploy

Tras haber tenido problemas con el PaaS *RailWay*, se decidió cambiar la plataforma de despliegue a *Google Cloud*. Esta plataforma nos ofrece más recursos, pero entra en un estado de hibernación tras su desuso. Para solucionar el problema de la hibernación se utilizó la página *UptimeRobot*, que nos permite realizar un _ping_ al https://averiapi-4vtuhnxfba-uc.a.run.app/[dominio] de la API. El _ping_ al dominio nos permite mantener "despierta" la API, y que al momento de consumirla no se desperdicie el tiempo en esperar que la API salga de su estado de hibernación.

== Bases de datos

Iniciamos una investigación de diferentes tipos de bases de datos para determinar la mejor base de datos a utilizar en el próximo sprint.

También, nos contactamos con el equipo de datos para definir detalles de nuestras dependencias, y compartir documentación para facilitar el proceso de elección y desarrollo de la base de datos.